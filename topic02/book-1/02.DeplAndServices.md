## Deployments.

In a agile development environment, utomation of application rollout and rollback is essential. Kubernetes Deployments support these requirements.

Create a file named `nginx-deployment.yaml`, and declare a deployment for a pod for a two-replica, single-container with an NGINX image:
~~~
apiVersion: apps/v1
kind:  Deployment
metadata:
  name: nginx-depl
  annotations:
     kubernetes.io/change-cause: "Initial deployment"
spec:
  replicas: 2
  selector:
     matchLabels:
        app: nginx-pod
  template:
    metadata:
      name: nginx-pod-spec
      labels:
        app: nginx-pod
    spec:
      containers:
      - name: nginx
        image: nginx:1.24.0
        ports:
        - containerPort: 80
~~~
Create this deployment will automatically generate a replicaset, and two pods:
~~~
$ oc apply -f nginx-deployment.yaml
$ oc get deploy                     
$ oc get rs       
$ oc get po
~~~
Notice that the replicaset's name is derived from the deployment's name, and the pod names are derived from the replicaset.

Check the two new pods are working using port-forwarding, as before.

To demonstrate self-healing, delete one of the pods, but check its IP address first:
~~~
$ oc get po -o wide
❯ oc delete pod nginx-depl-9b59dbbfc-4grnf  
$ oc get po -o wide
~~~
Kubernetes automatically recreates the pod, but it has a different IP address.

Commit the work so far:
~~~
$ git add -A
$ git commit -m "Creating deployment for NGINX replicaset."
~~~

### Services.

We place a service in front of a replicaset/deploymen due to the dynamic nature of pod IP allocationt.

Service declarations can be in a seperare file or together with its deployment. In  `nginx-deployment.yaml`, add a service declaration at the bottom, seperated by triple dash:
~~~
. . . deployment declaration . . . 

---

apiVersion: v1
kind: Service
metadata:
   name: nginx-service
spec:
   type: ClusterIP     # Default
   selector:           # How to match a service to a pod(s)
      app: nginx-pod
   ports:
     - port: 8080       # Port that the service receives requests
       targetPort: 80   # The container's port
~~~
Create the service (and notice the deployment is unchanged:)
~~~
$ oc apply -f nginx-deployment.yaml
$ oc get service                   
~~~
There may be some default services, as well as yours.
Run the same apply command again, and this time it responds that the service and deployment are unchanged. 

To prove the service is working, use port forwarding to the service (its listening on port 8080):
~~~
$ oc port-forward service/nginx-service  3001:8080
~~~
When using Port-forwarding with a service (the default is with pods), we must use a fully qualified name - service/nginx-service. In a browser tab, navigate to http://localhost:3001/. Stop port-forwarding.

The service we created is of type ClusterIP, which are typically invoked by other pods. Because Kubernetes performs domain name resolution, a pod can reference a service by name. To demo this, open an interactive terminal session with one of the httpd pods:
~~~
$ oc exec -it httpd-replica-bshfm   -- /bin/sh
# apt-get -y update
# apt-get -y install curl     (Some images includes curl, but HTTPD does not)
#
# curl nginx-service:8080
. . . . web page from one of the NGINX pods . . . 
# exit
~~~

A service load-balances between its associated pods. To prove this, we will add a line to bottom of the web page of the NGINX pods that shows the pods IP address.__For each__ of the NGINX pods complete the following sequence:
~~~
❯ oc exec -it nginx-depl-9b59dbbfc-jbhnv  -- /bin/sh
# echo "<h1>I'm pod $(hostname -i)</h1>" >> /usr/share/nginx/html/index.html
# exit
~~~

Now, open an interactive terminal session with the same httpd pods used above (it has curl installed) and call the NGINX service multiple times, say five times:
~~~
$ oc exec -it httpd-replica-bshfm   -- /bin/sh
#
# curl nginx-service:8080
# curl nginx-service:8080
# curl nginx-service:8080
# curl nginx-service:8080
# curl nginx-service:8080
# exit
$
$ oc get endpoints nginx-service   (Note the IP addresses of the service's two endpoints/pods)
~~~
You should notice the IP address at the bottom of the curl responses ossilates between the two NGINX pod IPs, thus proving that load balancing is occurring.

