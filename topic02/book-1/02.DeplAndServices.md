## Deployments.

Kubernetes's deployment resources are similar to replica sets, but they offer additional features that make them very useful in a production environment, such as rollouts and rollbacks.  

Create a file named `nginx-deployment.yaml`, and declare a deployment for two replica pods with a container running NGINX:
~~~
apiVersion: apps/v1
kind:  Deployment
metadata:
  name: nginx-depl
  annotations:
 kubernetes.io/change-cause: "Initial deployment"
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx-pod
  template:
    metadata:
      name: nginx-pod-spec
      labels:
         app: nginx-pod
    spec:
      serviceAccountName: bsc-ssd-y4-2025-sa
      containers:
      - name: nginx
        image: nginx:1.24.0
        ports:
        - containerPort: 80
~~~
Creating this deployment resource will automatically generate a replicaset resource, and two pod resources:
~~~
$ oc apply -f nginx-deployment.yaml
$ oc get deploy                     
$ oc get rs       
$ oc get po
~~~
Notice that the replicaset's name is derived from the deployment's name, and the pod names are derived from the replicaset name.

Check that the two new pods are working using port-forwarding, as before, and use the browser as the client.

To demonstrate __self-healing__, delete one of the pods, but check its IP address first:
~~~
$ oc get po -o wide
‚ùØ oc delete pod nginx-depl-9b59dbbfc-4grnf      (Use your pod name)
$ oc get po -o wide
~~~
Kubernetes automatically recreates the pod after the delete command, but it has a different IP address.

Commit the work so far:
~~~
$ git add -A
$ git commit -m "Creating deployment for NGINX replicaset."
~~~

### Services.

Services act as a stable interface to the set of pods managed by a replicaset/deployment. Recall, pod IP addresses are dynamic.

Service declarations can be in a separate file or included with their deployment manifest. In  `nginx-deployment.yaml`, add a service declaration at the bottom, separated by a triple-dash:
~~~
. . . deployment declaration . . . 

---

apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  type: ClusterIP     # Default
  selector:           # How to match a service to its pods.
    app: nginx-pod
  ports:
  - port: 8080       # Port that the service receives requests
    targetPort: 80   # The container's port
~~~
Create the file's resources, and notice that the service is created, but the deployment is unchanged:)
~~~
$ oc apply -f nginx-deployment.yaml
$ oc get service                   
~~~
There may be some default services, as well as yours in the response. Run the above apply command again, and this time it responds that the service and deployment are unchanged. 

To prove the service is working, use port forwarding (it's listening on port 8080):
~~~
$ oc port-forward service/nginx-service  3001:8080
~~~
When using Port-forwarding with a service (as opposed to a pod), we must use a fully qualified resource name, i.e. service/nginx-service. In a browser tab, navigate to http://localhost:3001/. Stop port-forwarding.

In general, pods communicate via services. Because Kubernetes performs domain name resolution, a pod can reference a service by its name rather than IP address. To demo this, open a terminal session with one of the httpd pods:
~~~
$ oc exec -it httpd-replica-bshfm   -- /bin/sh
# apt-get -y update
# apt-get -y install curl     (Some images includes curl, but HTTPD does not)
#
# curl http://nginx-service:8080
. . . . web page from one of the NGINX pods . . . 
# exit
~~~

#### Load balancing.

A service __load-balances__ between its associated pods. To prove this, we will add a line to the bottom of the NGINX home page that shows the IP address of its pod.__ For each__ of the NGINX pods in the replica set, complete the following sequence:
~~~
$ oc exec -it nginx-depl-9b59dbbfc-jbhnv  -- /bin/sh
# echo "<h1>I'm pod $(hostname -i)</h1>" >> /usr/share/nginx/html/index.html
# exit
~~~
[Repeat the above steps for the second NGINX pod]

Now, open an interactive terminal session with the same httpd pods used above (it has curl installed), and call the NGINX service multiple times, say five times:
~~~
$ oc exec -it httpd-replica-bshfm   -- /bin/sh
#
# curl http://nginx-service:8080
. . . . response . . . .
# curl http://nginx-service:8080
. . . . response . . . .
# curl http://nginx-service:8080
. . . . response . . . .
# curl http://nginx-service:8080
. . . . response . . . .
# curl http://nginx-service:8080
. . . . response . . . .
# curl http://nginx-service:8080

# exit
$
~~~
You should notice the IP address at the bottom of the responses ossilates between the two NGINX servers, thus proving that load balancing is occurring.

Commit the work so far:
~~~
$ git add -A
$ git commit -m "Creating service for NGINX pods."
~~~

A quick way to find the IP addresses of the pods a service interfaces to is:
~~~bash
$ oc get endpoints nginx-service
~~~