### Externalise Configuration.


### Cleanup.

Delete the MongoDB deployment:
~~~bash
$ oc delete deploy mongo-depl
~~~

### ConfigMap resource. 

The MongoDB deployment manifest has its configuration data hard-coded. A better approach is to externalise this using a ConfigMap resource. Create a new file `mongo-config.yaml` and add the following:
~~~yaml
apiVersion: v1
kind: ConfigMap
metadata: 
    name: mongodb-config
immutable: false
data:
    username: admin
    password: secret
    sample.conf: |
 This is a test file
 with multiple lines
~~~
The last data item (sample.conf) is a demonstraation of a configuration file to be used by a container image.

Create the resource:
~~~bash
$ oc apply -f  mongo-config.yaml
$ oc get cm                   (cm = ConfigMap)
$ oc describe cm mongodb-config                      
~~~

Update `mongo-deployment.yaml`by replacing the hardcoded data with references to the data in the ConfigMAP as shown below:
~~~yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mongo-depl
spec:
    . . . as before . . . 
    template:
         . . . as before . . .    
        spec:
             serviceAccountName: bsc-ssd-y4-2025-sa
             containers:
             - image: bitnami/mongodb:latest
                 name: mongo
                 env:
                 - name: MONGODB_ROOT_PASSWORD
                    valueFrom:
                        configMapKeyRef:
                            key: password
                            name: mongodb-config  
                 - name: MONGODB_ROOT_USER
                    valueFrom:
                         configMapKeyRef:
                            key: username
                            name: mongodb-config
                ports:
                - containerPort: 27017
                volumeMounts:
                - name: mongo-volume
                   mountPath: /bitnami/mongodb  # /data/db
                - name: mongo-config-test
                   mountPath: /bitnami

      volumes:
      - name: mongo-volume
          persistentVolumeClaim:
             claimName: my-mongo-pvc
      - name: mongo-config-test
         configMap:
            name: mongodb-config
                items:
                - key: sample.conf
                   path: test.conf
~~~
Note that the `sample.config` configuration item is mounted at `/bitnami/test.config` in the pod container

Create the deployment resource:
~~~bash
$ oc apply -f  mongo-deployment.yaml
$ oc get po
~~~
Check the pod container has the correct configuration:
~~~bash
 $ oc exec -it mongo-depl-57ffbd4cd7-kzdrb -- sh      
sh-5.2$ env                                                                                                        
. . . . . other environment variables , , , , 
MONGODB_ROOT_USER=admin
. . . . . other environment variables , , , , 
MONGODB_ROOT_PASSWORD=secret
. . . . . other environment variables , , , ,  
sh-5.2$ cat /bitnami/test.conf                                                                                     
This is a test file
with multiple lines
sh-5.2$ exit
~~~

In `mongo-config.yaml`:
+ Change the password to `private`.
+ Change sample.cpnfog by add a new line with some text.

Update the resource:
~~~bash
$ oc apply -f  mongo-config.yaml                    
~~~

Delete the MongoDB pod:
~~~bash
$ oc delete pod/mongo-demo-depl-69945f848c-k82z8       (Use your pod name)
~~~
Kubernetes recreates the pod. Start an interactive terminal session  (oc exec -it .....) and check the configuration updates are applied.

Commit this work:
~~~bash
$ git add -A
$ git commit -m "Creating  ConfigMap resource for database server."
~~~

### Secret resource. 

The database password should be stored in a Secret resource rather than in a ConfigMap. Create the file `mongo-secret.yaml`:
~~~yaml
apiVersion: v1
kind: Secret
metadata: 
    name: mongodb-secret
immutable: false
type: Opaque
data:
    password: TODO
~~~
The data in a Secret resource must be Base64 encoded. Suppose we want the password to be 'password1234'; the encoded value is:
~~~bash
$  echo -n password1234 | base64          
cGFzc3dvcmQxMjM0
~~~
In `mongo-secret.yaml`, change the password value:
~~~
     password: cGFzc3dvcmQxMjM0
~~~
Create the secret resource:
~~~bash
$ oc apply -f  mongo-secret.yaml
$ oc get  secret
$ oc describe  secret mongodb-secret                  
~~~

Update `mongo-deployment.yaml`by replacing the ConfigMap value for the password with the secret as shown below:
~~~yaml
 . . . . . as before
        spec:
             serviceAccountName: bsc-ssd-y4-2025-sa
             containers:
             - image: bitnami/mongodb:latest
                 name: mongo
                 env:
                 - name: MONGODB_ROOT_PASSWORD
                    valueFrom:
                        secretKeyRef:
                            key: password
                            name: mongodb-secret  
                 - name: MONGODB_ROOT_USER
                    valueFrom:
                         configMapKeyRef:
                            key: username
                            name: mongodb-config
    . . . . . . . as before . . . . . . .
~~~
This time we must update the deployment:
~~~bash
$ oc apply -f  mongo-deployment.yaml
~~~
Start an interactive terminal session with the MongoDB pod and check the environment variables, as before.

Commit this work:
~~~bash
$ git add -A
$ git commit -m "Creating  Secret resource for database server."
~~~


DynamoDB Streams.
Currently, the application sends an email to the user when a message about the image upload is placed in the mail queue. An alternative design for this feature is to trigger the emailing when the image’s database item is inserted, as illustrated below:



Code changes.
In lib/eda-stack.ts:

Add an import:
import * as source from "aws-cdk-lib/aws-lambda-event-sources";

Configure the table to generate a stream:
    const imagesTable = new dynamodb.Table(this, "ImagesTable", {
      billingMode: dynamodb.BillingMode.PAY_PER_REQUEST,
      partitionKey: { name: "name", type: dynamodb.AttributeType.STRING },
      removalPolicy: cdk.RemovalPolicy.DESTROY,
      tableName: "Imagess",
      stream: dynamodb.StreamViewType.NEW_IMAGE.         //. UPDATE
 });

Remove the code that sets the mail queue as the event source for the lambda:
mailerFn.addEventSource(newImageMailEventSource);

Remove the code that sets the subscription of the mail queue to the topic:
    newImageTopic.addSubscription(new subs.SqsSubscription(mailerQ), {
      . . . configuration . . . 
    });

Remove the code that sets sets the mail queue event source to triggers the lambda function:
    const newImageMailEventSource = new events.SqsEventSource(mailerQ, {
      batchSize: 5,
      maxBatchingWindow: cdk.Duration.seconds(5),
    }); 

Remove the mail SQS queue code:
    const mailerQ = new sqs.Queue(this, "mailer-q", {
      receiveMessageWaitTime: cdk.Duration.seconds(10),
    });

Set the DnamoDB stream as the event source for the lambda: the Dy
    mailerFn.addEventSource(
      new source.DynamoEventSource(imagesTable, {
        startingPosition: lambda.StartingPosition.LATEST
 })
 )

The lambda function must change because its event source has switched from the SQS queue to the DynamoDB stream. In lambdas/mailer.ts,

Add some imports:
import { DynamoDBStreamHandler } from "aws-lambda";
import { unmarshall } from "@aws-sdk/util-dynamodb";

Replace the handler function with the following:
export const handler: DynamoDBStreamHandler = async (event: any) => {
  console.log("Event ", JSON.stringify(event));
  for (const record of event.Records) {
    if (record.eventName == "INSERT") {
      const dbItem = unmarshall(record.dynamodb.NewImage);
      try {
        const { name, email, message }: ContactDetails = {
          name: "The Photo Album",
          email: SES_EMAIL_FROM,
          message: `We received your Image ${dbItem.name}`,
 };
        const params = sendEmailParams({ name, email, message });
        await client.send(new SendEmailCommand(params));
 } catch (error: unknown) {
        console.log("ERROR is: ", error);
        // return;
 }

Update the stack:

$ cdk deploy

And upload an image to the bucket. You should still receive an email confirmation. In CloudWatch logs, check the log stream for the mailer function.

Commit this work:

$ git add -A
$ git commit -m "Change mailer trigger to the DB stream.."
$ git push origin main

## Submission.
Create a text file called ‘edaLabWork.txt’ and paste the URL of your GitHub repo into it. Log in to it. Log in to Moodle and submit the text file at [this link][submit].

[submit]: https://moodle.setu.ie/mod/assign/view.php?id=4618510

